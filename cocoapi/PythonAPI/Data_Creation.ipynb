{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, glob\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import json\n",
    "from skimage import data, img_as_float\n",
    "from skimage import exposure\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=11.71s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annFile='../../annotations/instances_train2014.json'\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "COCO categories: \nperson bicycle car motorcycle airplane bus train truck boat traffic light fire hydrant stop sign parking meter bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard sports ball kite baseball bat baseball glove skateboard surfboard tennis racket bottle wine glass cup fork knife spoon bowl banana apple sandwich orange broccoli carrot hot dog pizza donut cake chair couch potted plant bed dining table toilet tv laptop mouse remote keyboard cell phone microwave oven toaster sink refrigerator book clock vase scissors teddy bear hair drier toothbrush\n\nCOCO supercategories: \nkitchen animal appliance electronic food indoor outdoor sports furniture vehicle person accessory\n"
     ]
    }
   ],
   "source": [
    "#  Displaying coco categories and subcategories to choose from. Rather than choosing from one category we will choose combination of multiple categories.\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "# get all images containing given categories, select one at random\n",
    "# person, surfboard -- Category combo 1\n",
    "# person dog - Category combo 2\n",
    "catIds = coco.getCatIds(catNms=['person','surfboard']);\n",
    "imgIds1 = coco.getImgIds(catIds=catIds);\n",
    "imgIds1 = imgIds1[:100]\n",
    "catIds = coco.getCatIds(catNms=['person','dog']);\n",
    "imgIds2 = coco.getImgIds(catIds=catIds);\n",
    "imgIds2 = imgIds2[:100]\n",
    "imgIds = imgIds1 + imgIds2\n",
    "imgIds = list(dict.fromkeys(imgIds))\n",
    "print(len(imgIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in imgIds:\n",
    "    img = coco.loadImgs(x)[0]\n",
    "    I = io.imread(img['coco_url'])\n",
    "    path = os.path.join('../../dataCreate/', str(x))\n",
    "    os.mkdir(path)\n",
    "    io.imsave(os.path.join(path, '{}.png'.format(x)), I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x720 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# load and display instance annotations\n",
    "for x in imgIds:\n",
    "    img = coco.loadImgs(x)[0]\n",
    "    I = io.imread(img['coco_url'])\n",
    "    plt.imshow(I); plt.axis('off')\n",
    "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    imgA = coco.showAnns(anns)\n",
    "    plt.savefig('../../dataCreate/{}/{}_Annotated'.format(x,x))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.80s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for caption annotations\n",
    "annFile = '../../annotations/captions_train2014.json'\n",
    "coco_caps=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load and display caption annotations\n",
    "for x in imgIds:\n",
    "    annIds = coco_caps.getAnnIds(imgIds=x);\n",
    "    anns = coco_caps.loadAnns(annIds)\n",
    "    with open('../../dataCreate/{}/{}.json'.format(x,x), 'w') as outfile:\n",
    "        json.dump(anns, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposes(filename, dirpath):\n",
    "    path = os.path.join(dirpath,filename)\n",
    "    im = Image.open(path)\n",
    "    hf = im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "    hf.save(\"{}/hf_{}\".format(dirpath, filename))\n",
    "    vf = im.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
    "    vf.save(\"{}/vf_{}\".format(dirpath, filename))\n",
    "    r90 = im.transpose(PIL.Image.ROTATE_90)\n",
    "    r90.save(\"{}/r90_{}\".format(dirpath, filename))\n",
    "    r180 = im.transpose(PIL.Image.ROTATE_180)\n",
    "    r180.save(\"{}/r180_{}\".format(dirpath, filename))\n",
    "    r270 = im.transpose(PIL.Image.ROTATE_270)\n",
    "    r270.save(\"{}/r270_{}\".format(dirpath, filename))\n",
    "    r45 = im.rotate(45, PIL.Image.NEAREST, expand = 1)\n",
    "    r45.save(\"{}/r135_{}\".format(dirpath, filename))\n",
    "    r135 = im.rotate(135, PIL.Image.NEAREST, expand = 1)\n",
    "    r135.save(\"{}/r135_{}\".format(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exposures(filename, dirpath):\n",
    "    path = os.path.join(dirpath,filename)\n",
    "    im = Image.open(path)\n",
    "    img = np.asanyarray(im)\n",
    "\n",
    "    # Contrast stretching\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "\n",
    "    # Histogram Equalization\n",
    "    img_eq = exposure.equalize_hist(img)\n",
    "\n",
    "    # Adaptive Equalization\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "\n",
    "    #  Saving Images\n",
    "    cv2.imwrite(\"{}/cvr_{}\".format(dirpath, filename), img_rescale)\n",
    "    im_re = Image.fromarray(img_rescale)\n",
    "    im_re.save(\"{}/IR_{}\".format(dirpath, filename))\n",
    "\n",
    "    im_eq = Image.fromarray((img_eq * 255).astype(np.uint8))\n",
    "    im_eq.save(\"{}/IE_{}\".format(dirpath, filename))\n",
    "\n",
    "    im_ad = Image.fromarray((img_adapteq * 255).astype(np.uint8))\n",
    "    im_ad.save(\"{}/IA_{}\".format(dirpath, filename))\n",
    "\n",
    "    cv2.imwrite(\"{}/cve_{}\".format(dirpath, filename), (img_eq * 255).astype(np.uint8))\n",
    "\n",
    "    cv2.imwrite(\"{}/cva_{}\".format(dirpath, filename), (img_adapteq * 255).astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PosixPath('/Users/manvishn/refcoco/cocoapi/PythonAPI')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import pathlib\n",
    "pathlib.Path().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "directory = \"/Users/manvishn/refcoco/dataCreate\"\n",
    "for (dirpath, dirnames, filenames) in walk(directory):\n",
    "    for f in filenames:\n",
    "         if f.endswith('.png'):\n",
    "            exposures(f, dirpath)\n",
    "            transposes(f, dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (dirpath, dirnames, filenames) in walk(directory):\n",
    "    for f in filenames:\n",
    "         if f.endswith('.png') and 'Annotated' not in f:\n",
    "             with open(os.path.join(dirpath,dirpath.split('/')[-1]+'.json')) as json_file:\n",
    "                data = json.load(json_file)\n",
    "             refs = []\n",
    "             for x in data:\n",
    "                 refs.append(x['caption'])\n",
    "             refs = random.sample(refs,3)\n",
    "             dict = {\n",
    "                 \"filename\":f,\n",
    "                 \"segmented_filename\": f.split('.')[0]+'_Annotated.png',\n",
    "                 \"references\": refs\n",
    "             }\n",
    "             dataset.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json = {\n",
    "    \"Name\": \"Aradhana Trivedi\",\n",
    "    \"ASUID\": 1217102484,\n",
    "    \"images\":dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_json.json', 'w') as outfile:\n",
    "    json.dump(final_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('envP': venv)",
   "display_name": "Python 3.8.6 64-bit ('envP': venv)",
   "metadata": {
    "interpreter": {
     "hash": "7b7139962748f06fe975f78faf291c82a292e7e72833b784f2ab137f19982d6e"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}